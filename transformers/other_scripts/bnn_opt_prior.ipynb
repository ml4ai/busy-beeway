{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a43c50-c96d-41d9-bbf4-3d1bc09e2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cb71a-45d1-4d08-af70-c4151a8375b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import orbax.checkpoint as ocp\n",
    "from flax import nnx\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "\n",
    "import transformers.models.mean_functions as mean_functions\n",
    "from transformers.models import kernels, normalization\n",
    "from transformers.models.b_mlp import GaussianMLPReparameterization\n",
    "from transformers.models.bnn_likelihoods import LikGaussian\n",
    "from transformers.models.bnn_priors import FixedGaussianPrior\n",
    "from transformers.models.gp import GPR\n",
    "from transformers.models.mlp import MLP\n",
    "from transformers.models.rand_generators import GridGenerator\n",
    "from transformers.training import utils\n",
    "from transformers.training.jax_utils import vgrad\n",
    "from transformers.training.wasserstein_mapper import MapperWasserstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a129e-44ad-4e08-9609-8d23982163e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c6394-4b23-4c5d-bd8f-f03992b03663",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.expanduser(\n",
    "    \"~/busy-beeway/transformers/exp/1D_synthetic/tanh_gaussian_new\"\n",
    ")\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
    "utils.ensure_dir(OUT_DIR)\n",
    "utils.ensure_dir(FIG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea584baf-fe76-4c49-a7c7-cd1e2d4a293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2591140-70a5-48bc-a9a1-0c7f65d2e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_gap(X, gap_ratio=0.2, rng=np.random.default_rng()):\n",
    "    a, b = X.min(), X.max()\n",
    "    gap_a = a + rng.random() * (b - a) * (1 - gap_ratio)\n",
    "    gap_b = gap_a + (b - a) * gap_ratio\n",
    "    idx = np.logical_and(gap_a < X, X < gap_b)\n",
    "    if gap_a - a > b - gap_b:\n",
    "        X[idx] = a + rng.random(idx.sum()) * (gap_a - a)\n",
    "    else:\n",
    "        X[idx] = gap_b + rng.random(idx.sum()) * (b - gap_b)\n",
    "\n",
    "\n",
    "def gp_sample(X, ampl=1, leng=1, sn2=0.1, rng=np.random.default_rng()):\n",
    "    n, x = X.shape[0], X / leng\n",
    "    sum_xx = np.sum(x * x, 1).reshape(-1, 1).repeat(n, 1)\n",
    "    D = sum_xx + sum_xx.transpose() - 2 * np.matmul(x, x.transpose())\n",
    "    C = ampl**2 * np.exp(-0.5 * D) + np.eye(n) * sn2\n",
    "    return rng.multivariate_normal(np.zeros(n), C).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def plot_samples(\n",
    "    X,\n",
    "    samples,\n",
    "    var=None,\n",
    "    n_keep=12,\n",
    "    color=\"xkcd:bluish\",\n",
    "    smooth_q=False,\n",
    "    ax=None,\n",
    "    rng=np.random.default_rng(),\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if samples.ndim > 2:\n",
    "        samples = samples.squeeze()\n",
    "    n_keep = int(samples.shape[1] / 10) if n_keep is None else n_keep\n",
    "    keep_idx = rng.permutation(samples.shape[1])[:n_keep]\n",
    "    mu = samples.mean(1)\n",
    "    if var is None:\n",
    "        q = 97.72  ## corresponds to 2 stdevs in Gaussian\n",
    "        # q = 99.99  ## corresponds to 3 std\n",
    "        Q = np.percentile(samples, [100 - q, q], axis=1)\n",
    "        # ub, lb = Q[1,:], Q[0,:]\n",
    "        ub, lb = mu + 2 * samples.std(1), mu - 2 * samples.std(1)\n",
    "        if smooth_q:\n",
    "            lb = moving_average(lb)\n",
    "            ub = moving_average(ub)\n",
    "    else:\n",
    "        ub = mu + 3 * np.sqrt(var)\n",
    "        lb = mu - 3 * np.sqrt(var)\n",
    "    ####\n",
    "    ax.fill_between(X.flatten(), ub, lb, color=color, alpha=0.25, lw=0)\n",
    "    ax.plot(X, samples[:, keep_idx], color=color, alpha=0.8)\n",
    "    ax.plot(X, mu, color=\"xkcd:red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a650e9-aa97-40e7-b096-60cb479a0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "M = 100\n",
    "a, b = -10, 10\n",
    "\n",
    "# Generate data\n",
    "X = rng.random((N, 1)) * (b - a) + a\n",
    "make_random_gap(X, gap_ratio=0.4, rng=rng)\n",
    "y = gp_sample(X, ampl=1.6, leng=1.8, rng=rng)\n",
    "Xtest = np.linspace(a - 5, b + 5, M).reshape(-1, 1)\n",
    "\n",
    "# Normalize the dataset\n",
    "X_, X_mean, X_std = normalization.zscore_normalization(X)\n",
    "y_, y_mean, y_std = normalization.zscore_normalization(y)\n",
    "Xtest_, _, _ = normalization.zscore_normalization(Xtest, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0419d0a-fb0d-4fde-b17f-6f6d22138958",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(X, y, \"ko\", ms=5)\n",
    "plt.title(\"Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f957f0b-67cd-4f2f-b184-2ddeda22d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP hyper-parameters\n",
    "rngs = nnx.Rngs(12345)\n",
    "sn2 = 0.1  # noise variance\n",
    "leng = 0.6  # lengthscale\n",
    "ampl = 1.0  # amplitude\n",
    "\n",
    "# Initialize GP Prior\n",
    "kernel = kernels.RBF(\n",
    "    input_dim=1,\n",
    "    ARD=True,\n",
    "    lengthscales=jnp.array([leng], dtype=jnp.double),\n",
    "    variance=jnp.array([ampl], dtype=jnp.double),\n",
    ")\n",
    "\n",
    "gpmodel = GPR(\n",
    "    X=X_,\n",
    "    Y=y_.reshape((-1, 1)),\n",
    "    kern=kernel,\n",
    "    mean_function=mean_functions.Zero(),\n",
    "    jitter_level=5e-5,\n",
    "    rngs=rngs,\n",
    ")\n",
    "gpmodel.likelihood.variance.set(sn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fbb96-b298-463b-a282-2226b6383b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BNN Priors\n",
    "width = 50  # Number of units in each hidden layer\n",
    "depth = 3  # Number of hidden layers\n",
    "transfer_fn = \"tanh\"  # Activation function\n",
    "\n",
    "# Initialize Gaussian prior.\n",
    "# Fixed Prior\n",
    "std_bnn = GaussianMLPReparameterization(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    activation_fn=transfer_fn,\n",
    "    hidden_dims=[width] * depth,\n",
    "    rngs=rngs,\n",
    ")\n",
    "\n",
    "# Prior to be optimized\n",
    "opt_bnn = GaussianMLPReparameterization(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    activation_fn=transfer_fn,\n",
    "    hidden_dims=[width] * depth,\n",
    "    rngs=rngs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6198644-45e4-455d-8875-ac654b1cfd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = GridGenerator(-6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09b797-d290-4653-b9e9-791ac92dd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_num_iters = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148aef1-fd64-415e-9515-766a86163f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper = MapperWasserstein(\n",
    "#     gpmodel,\n",
    "#     opt_bnn,\n",
    "#     data_generator,\n",
    "#     out_dir=OUT_DIR,\n",
    "#     wasserstein_steps=(0, 1000),\n",
    "#     wasserstein_lr=0.08,\n",
    "#     n_data=200,\n",
    "#     rngs=rngs,\n",
    "# )\n",
    "\n",
    "# # Start optimizing the prior\n",
    "# w_hist = mapper.optimize(\n",
    "#     num_iters=mapper_num_iters,\n",
    "#     n_samples=512,\n",
    "#     lr=0.01,\n",
    "#     save_ckpt_every=50,\n",
    "#     print_every=20,\n",
    "# )\n",
    "# path = os.path.join(OUT_DIR, \"wsr_values.log\")\n",
    "# np.savetxt(path, w_hist, fmt=\"%.6e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808ff84-0613-4868-b890-f9ceaca98390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize progression of the prior optimization\n",
    "wdist_file = os.path.join(OUT_DIR, \"wsr_values.log\")\n",
    "wdist_vals = np.loadtxt(wdist_file)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.5))\n",
    "indices = np.arange(mapper_num_iters)[::5]\n",
    "plt.plot(indices, wdist_vals[indices], \"-ko\", ms=4)\n",
    "plt.ylabel(r\"$W_1(p_{gp}, p_{nn})$\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796eb63-82c3-4cad-9a87-5431eaac797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(OUT_DIR, \"ckpts\", \"it-{}.ckpt\".format(mapper_num_iters))\n",
    "checkpointer = ocp.StandardCheckpointer()\n",
    "empty_bnn = GaussianMLPReparameterization(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    activation_fn=transfer_fn,\n",
    "    hidden_dims=[width] * depth,\n",
    "    rngs=rngs,\n",
    ")\n",
    "utils.prng_to_raw(empty_bnn)\n",
    "abstract_bnn = nnx.eval_shape(lambda: empty_bnn)\n",
    "graphdef, abstract_state = nnx.split(abstract_bnn)\n",
    "state_restored = checkpointer.restore(ckpt_path, abstract_state)\n",
    "opt_bnn = nnx.merge(graphdef, state_restored)\n",
    "utils.raw_to_prng(opt_bnn)\n",
    "checkpointer.wait_until_finished()\n",
    "checkpointer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e560d5-0dcc-49dd-a6a8-9199c083b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw functions from the priors\n",
    "n_plot = 4000\n",
    "\n",
    "gp_samples = gpmodel.sample_functions(jnp.float32(Xtest_), n_plot).squeeze()\n",
    "\n",
    "gp_samples = normalization.zscore_unnormalization(gp_samples, y_mean, y_std)\n",
    "\n",
    "std_bnn_samples = std_bnn.sample_functions(jnp.float32(Xtest_), n_plot).squeeze()\n",
    "\n",
    "std_bnn_samples = normalization.zscore_unnormalization(std_bnn_samples, y_mean, y_std)\n",
    "\n",
    "opt_bnn_samples = opt_bnn.sample_functions(jnp.float32(Xtest_), n_plot).squeeze()\n",
    "\n",
    "opt_bnn_samples = normalization.zscore_unnormalization(opt_bnn_samples, y_mean, y_std)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 3))\n",
    "plot_samples(Xtest, gp_samples, ax=axs[0], n_keep=5, rng=rng)\n",
    "axs[0].set_title(\"GP Prior\")\n",
    "axs[0].set_ylim([-5, 5])\n",
    "\n",
    "plot_samples(Xtest, std_bnn_samples, ax=axs[1], color=\"xkcd:grass\", n_keep=5, rng=rng)\n",
    "axs[1].set_title(\"BNN Prior (Fixed)\")\n",
    "axs[1].set_ylim([-5, 5])\n",
    "\n",
    "plot_samples(\n",
    "    Xtest, opt_bnn_samples, ax=axs[2], color=\"xkcd:yellowish orange\", n_keep=5, rng=rng\n",
    ")\n",
    "axs[2].set_title(\"BNN Prior (GP-induced)\")\n",
    "axs[2].set_ylim([-5, 5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f4a7a-6922-4bbb-8560-a384e4a08ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_preds = gpmodel.predict_f_samples(Xtest_, 1000)\n",
    "gp_preds = gp_preds.squeeze()\n",
    "gp_preds = normalization.zscore_unnormalization(gp_preds, y_mean, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbff874-b0ca-4685-a311-d3f708efd55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGHMC Hyper-parameters\n",
    "sampling_configs = {\n",
    "    \"batch_size\": 32,  # Mini-batch size\n",
    "    \"num_samples\": 30,  # Total number of samples for each chain\n",
    "    \"n_discarded\": 10,  # Number of the first samples to be discared for each chain\n",
    "    \"num_burn_in_steps\": 2000,  # Number of burn-in steps\n",
    "    \"keep_every\": 200,  # Thinning interval\n",
    "    \"lr\": 0.01,  # Step size\n",
    "    \"num_chains\": 4,  # Number of chains\n",
    "    \"mdecay\": 0.01,  # Momentum coefficient\n",
    "    \"print_every_n_samples\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3a06c-437c-4a73-8157-a001491a1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rngs = nnx.Rngs(8675)\n",
    "prior = FixedGaussianPrior(std=1.0)\n",
    "\n",
    "# Setup likelihood\n",
    "net = MLP(1, 1, [width] * depth, transfer_fn, rngs)\n",
    "likelihood = LikGaussian(sn2)\n",
    "\n",
    "# Initialize the sampler\n",
    "saved_dir = os.path.join(OUT_DIR, \"sampling_std\")\n",
    "utils.ensure_dir(saved_dir)\n",
    "bayes_net_std = RegressionNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "\n",
    "# # Start sampling\n",
    "# bayes_net_std.sample_multi_chains(X, y, **sampling_configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
